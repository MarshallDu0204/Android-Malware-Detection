{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"manifest.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZuuKzRob9g5Ki8nfgiD23"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EEA0FietYGha","executionInfo":{"status":"ok","timestamp":1612742249058,"user_tz":300,"elapsed":276,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}}},"source":["import csv\n","import os\n","\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Embedding,Dense,Bidirectional,LSTM,Dropout,TimeDistributed,Flatten,InputSpec,MaxPooling1D\n","from keras.callbacks import ModelCheckpoint\n","from keras import Input,Model\n","from keras import backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers as initializers, regularizers, constraints\n","\n","from sklearn import tree\n","from sklearn import svm\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import AdaBoostClassifier"],"execution_count":144,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ktujh2FuYMNi","executionInfo":{"status":"ok","timestamp":1612736207454,"user_tz":300,"elapsed":20060,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}},"outputId":"51c8f00e-a821-4921-880a-ce3548188217"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UVmIlqTBYKrz"},"source":["def manifest_data(path = 'drive/MyDrive/Colab Notebooks/apk_manifest.csv',dim = 2,one_hot = True,whole_data = False,binary_label = False):#dim = 3 if use lstm network\n","    with open(path) as f:\n","        reader = csv.reader(f)\n","        data = list(reader)\n","        trainData = []\n","        label = []\n","        \n","        for i in range(len(data)):\n","            templine = data[i]\n","            dataline = []\n","            for item in templine:\n","                dataline.append(int(item))\n","            trainData.append(dataline[:len(dataline)-1])\n","\n","            if binary_label == False:\n","                label.append(dataline[len(dataline)-1])\n","            else:\n","                if dataline[len(dataline)-1] == 0:\n","                    label.append(0)\n","                else:\n","                    label.append(1)\n","\n","        label = np.array(label)\n","\n","        if one_hot:\n","\n","            if binary_label:\n","                label = keras.utils.to_categorical(label,num_classes = 2)\n","            \n","            else:\n","                label = keras.utils.to_categorical(label,num_classes = 5)\n","\n","        trainData = np.array(trainData)\n","\n","        if dim == 3:\n","            trainData = np.reshape(trainData,(len(trainData),330,1))\n","\n","        if whole_data == True:\n","            \n","            return trainData,label\n","\n","        elif whole_data == False:\n","\n","            data_train, data_test, label_train, label_test = train_test_split(trainData,label,test_size=0.2,random_state=None,shuffle=True)\n","            \n","            return data_train,data_test,label_train,label_test\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_pI8fxWYmqz","executionInfo":{"status":"ok","timestamp":1612740582130,"user_tz":300,"elapsed":2989,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}},"outputId":"b8ec7b7f-891b-4a6e-ab8d-77727c0bc89c"},"source":["data,label = manifest_data(dim = 2,one_hot = False,whole_data = True,binary_label=False)\n","#print(data_train)\n","clf = svm.SVC()\n","#clf = LogisticRegression(random_state=0)\n","#clf = tree.DecisionTreeClassifier()\n","#clf.fit(data, label)\n","#clf = GaussianNB()\n","#clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n","#pred = clf.predict(data_test)\n","#print(pred)\n","scores = cross_val_score(clf, data, label, cv=5,scoring='accuracy')\n","print(scores.mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.8713037992153152\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yXtLeXCNg7Sa","executionInfo":{"status":"ok","timestamp":1612744048887,"user_tz":300,"elapsed":374,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}}},"source":["class MLP():\n","\n","    data_train = \"\"\n","    data_test = \"\"\n","    label_train = \"\"\n","    label_test = \"\"\n","\n","    def __init__(self,data_train,data_test,label_train,label_test):\n","        self.data_train = data_train\n","        self.data_test = data_test\n","        self.label_train = label_train\n","        self.label_test = label_test\n","\n","    def mlpModel(self,pretrained_weights = None):\n","\n","        input = Input(shape = (330,))\n","\n","        hiddenLayer = Dense(256,activation='relu')(input)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","\n","        hiddenLayer = Dense(256,activation='relu')(hiddenLayer)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","\n","        hiddenLayer = Dense(256,activation='relu')(hiddenLayer)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","        \n","        hiddenLayer = Dense(256,activation='relu')(hiddenLayer)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","\n","        output = Dense(5,activation = 'softmax')(hiddenLayer)\n","\n","        model = Model(inputs=input, outputs=[output])\n","\n","        model.compile(\n","            optimizer='rmsprop',\n","            loss='categorical_crossentropy',\n","            metrics=['acc']\n","        )\n","\n","        if (pretrained_weights):\n","            model.load_weights(pretrained_weights)\n","\n","        return model\n","    \n","    def train(self,model):\n","\n","        model_checkpoint = ModelCheckpoint('mlp.hdf5',monitor = 'loss',verbose = 1,save_best_only = True)\n","\n","        history = model.fit(\n","            x = self.data_train,\n","            y = self.label_train,\n","            validation_data = (self.data_test,self.label_test),\n","            batch_size = 64,\n","            epochs = 50,\n","            callbacks = [model_checkpoint]\n","        )\n","\n","        return history.history['loss'],history.history['acc'],history.history['val_loss'],history.history['val_loss']\n","\n","class BLSTM():\n","\n","    data_train = \"\"\n","    data_test = \"\"\n","    label_train = \"\"\n","    label_test = \"\"\n","\n","    def __init__(self,data_train,data_test,label_train,label_test):\n","        self.data_train = data_train\n","        self.data_test = data_test\n","        self.label_train = label_train\n","        self.label_test = label_test\n","\n","    \n","    def lstmModel_timedis(self,pretrained_weights = None):\n","\n","        inputContent = Input(shape = (330,1),name = 'content')\n","\n","        lstmContent = Bidirectional(LSTM(128,return_sequences=True),merge_mode='ave')(inputContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        lstmContent = Bidirectional(LSTM(128,return_sequences=True),merge_mode='ave')(inputContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        lstmContent = Bidirectional(LSTM(128,return_sequences=True),merge_mode='ave')(inputContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        lstmContent = Bidirectional(LSTM(128,return_sequences=True),merge_mode='ave')(lstmContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        output = TimeDistributed(Dense(128,activation='relu'))(lstmContent)\n","        output = Dropout(0.2)(output)\n","\n","        output = Flatten()(output)\n","\n","        output = Dense(128,activation='relu')(output)\n","        output = Dropout(0.2)(output)\n","        \n","        output = Dense(5,activation = 'softmax')(output)\n","\n","        model = Model(inputs=inputContent, outputs=[output])\n","\n","        model.compile(\n","            optimizer='rmsprop',\n","            loss='categorical_crossentropy',\n","            metrics=['acc']\n","        )\n","\n","        if (pretrained_weights):\n","            model.load_weights(pretrained_weights)\n","\n","        return model\n","\n","    def train(self,model):\n","\n","        model_checkpoint = ModelCheckpoint('blstm.hdf5',monitor = 'loss',verbose = 1,save_best_only = True)\n","\n","        history = model.fit(\n","            x = self.data_train,\n","            y = self.label_train,\n","            validation_data = (self.data_test,self.label_test),\n","            batch_size = 32,\n","            epochs = 50,\n","            callbacks = [model_checkpoint]\n","        )\n","\n","        print(history.history)\n","\n","        return history.history['loss'],history.history['acc'],history.history['val_loss'],history.history['val_acc']\n","\n"],"execution_count":168,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNBA1X8QkH0n","executionInfo":{"status":"ok","timestamp":1612744049977,"user_tz":300,"elapsed":311,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}}},"source":["def writeResult(model_name,loss,acc,val_loss,val_acc):\n","    filePath = 'drive/MyDrive/Colab Notebooks/'+str(model_name)+'.txt'\n","    with open(filePath,'a') as f:\n","        pass\n","\n","\n","def main():\n","    data_train,data_test,label_train,label_test = manifest_data(dim = 3)\n","    rnn = BLSTM(data_train,data_test,label_train,label_test)\n","    model = rnn.lstmModel_timedis()\n","    #model.summary()\n","    \n","    loss,acc,val_loss,val_acc = rnn.train(model)\n","\n","\n","    #data_train,data_test,label_train,label_test = manifest_data(dim = 2)\n","    \n","    #mlp_model = MLP(data_train,data_test,label_train,label_test)\n","    #model = mlp_model.mlpModel()\n","\n","    #loss,acc,val_loss,val_acc = mlp_model.train(model)\n","\n"],"execution_count":169,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyll1MxqkJpp","executionInfo":{"status":"ok","timestamp":1612744207388,"user_tz":300,"elapsed":155401,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}},"outputId":"8527b96f-19aa-4478-f039-33d48eaff943"},"source":["main()"],"execution_count":170,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","40/40 [==============================] - 9s 106ms/step - loss: 1.2547 - acc: 0.6814 - val_loss: 0.8861 - val_acc: 0.7053\n","\n","Epoch 00001: loss improved from inf to 1.06189, saving model to blstm.hdf5\n","Epoch 2/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.7514 - acc: 0.7663 - val_loss: 1.0166 - val_acc: 0.7273\n","\n","Epoch 00002: loss improved from 1.06189 to 0.72384, saving model to blstm.hdf5\n","Epoch 3/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.6184 - acc: 0.8183 - val_loss: 0.6272 - val_acc: 0.7994\n","\n","Epoch 00003: loss improved from 0.72384 to 0.62544, saving model to blstm.hdf5\n","Epoch 4/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.5124 - acc: 0.8547 - val_loss: 0.6267 - val_acc: 0.8088\n","\n","Epoch 00004: loss improved from 0.62544 to 0.51102, saving model to blstm.hdf5\n","Epoch 5/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.4991 - acc: 0.8477 - val_loss: 0.6179 - val_acc: 0.8119\n","\n","Epoch 00005: loss improved from 0.51102 to 0.48778, saving model to blstm.hdf5\n","Epoch 6/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.4141 - acc: 0.8726 - val_loss: 0.5982 - val_acc: 0.7931\n","\n","Epoch 00006: loss improved from 0.48778 to 0.41742, saving model to blstm.hdf5\n","Epoch 7/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.3913 - acc: 0.8731 - val_loss: 0.5152 - val_acc: 0.8401\n","\n","Epoch 00007: loss improved from 0.41742 to 0.41044, saving model to blstm.hdf5\n","Epoch 8/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.3646 - acc: 0.8732 - val_loss: 0.5475 - val_acc: 0.8307\n","\n","Epoch 00008: loss improved from 0.41044 to 0.38010, saving model to blstm.hdf5\n","Epoch 9/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.3386 - acc: 0.8994 - val_loss: 0.5529 - val_acc: 0.8339\n","\n","Epoch 00009: loss improved from 0.38010 to 0.35000, saving model to blstm.hdf5\n","Epoch 10/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.3308 - acc: 0.8954 - val_loss: 0.5806 - val_acc: 0.8150\n","\n","Epoch 00010: loss improved from 0.35000 to 0.32654, saving model to blstm.hdf5\n","Epoch 11/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.3348 - acc: 0.8926 - val_loss: 0.7459 - val_acc: 0.8370\n","\n","Epoch 00011: loss improved from 0.32654 to 0.30260, saving model to blstm.hdf5\n","Epoch 12/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.2786 - acc: 0.9064 - val_loss: 0.6362 - val_acc: 0.8589\n","\n","Epoch 00012: loss did not improve from 0.30260\n","Epoch 13/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.2622 - acc: 0.9239 - val_loss: 0.5738 - val_acc: 0.8621\n","\n","Epoch 00013: loss improved from 0.30260 to 0.27177, saving model to blstm.hdf5\n","Epoch 14/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.2475 - acc: 0.9232 - val_loss: 0.5091 - val_acc: 0.8871\n","\n","Epoch 00014: loss improved from 0.27177 to 0.26218, saving model to blstm.hdf5\n","Epoch 15/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.2072 - acc: 0.9369 - val_loss: 0.5063 - val_acc: 0.8746\n","\n","Epoch 00015: loss improved from 0.26218 to 0.24045, saving model to blstm.hdf5\n","Epoch 16/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.2394 - acc: 0.9258 - val_loss: 0.5669 - val_acc: 0.8527\n","\n","Epoch 00016: loss improved from 0.24045 to 0.23196, saving model to blstm.hdf5\n","Epoch 17/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.2036 - acc: 0.9373 - val_loss: 0.5210 - val_acc: 0.8621\n","\n","Epoch 00017: loss improved from 0.23196 to 0.21106, saving model to blstm.hdf5\n","Epoch 18/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.2088 - acc: 0.9349 - val_loss: 0.6544 - val_acc: 0.8746\n","\n","Epoch 00018: loss improved from 0.21106 to 0.20588, saving model to blstm.hdf5\n","Epoch 19/50\n","40/40 [==============================] - 3s 73ms/step - loss: 0.1360 - acc: 0.9524 - val_loss: 0.5597 - val_acc: 0.8840\n","\n","Epoch 00019: loss improved from 0.20588 to 0.19070, saving model to blstm.hdf5\n","Epoch 20/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1343 - acc: 0.9623 - val_loss: 0.5530 - val_acc: 0.8840\n","\n","Epoch 00020: loss improved from 0.19070 to 0.16744, saving model to blstm.hdf5\n","Epoch 21/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1468 - acc: 0.9512 - val_loss: 0.5856 - val_acc: 0.8652\n","\n","Epoch 00021: loss improved from 0.16744 to 0.15806, saving model to blstm.hdf5\n","Epoch 22/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.1290 - acc: 0.9590 - val_loss: 0.6296 - val_acc: 0.8370\n","\n","Epoch 00022: loss did not improve from 0.15806\n","Epoch 23/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1311 - acc: 0.9565 - val_loss: 0.7153 - val_acc: 0.8777\n","\n","Epoch 00023: loss improved from 0.15806 to 0.14665, saving model to blstm.hdf5\n","Epoch 24/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.1139 - acc: 0.9624 - val_loss: 0.8007 - val_acc: 0.8683\n","\n","Epoch 00024: loss improved from 0.14665 to 0.13394, saving model to blstm.hdf5\n","Epoch 25/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1317 - acc: 0.9590 - val_loss: 0.6220 - val_acc: 0.8966\n","\n","Epoch 00025: loss improved from 0.13394 to 0.12946, saving model to blstm.hdf5\n","Epoch 26/50\n","40/40 [==============================] - 3s 73ms/step - loss: 0.1447 - acc: 0.9606 - val_loss: 0.7462 - val_acc: 0.8777\n","\n","Epoch 00026: loss did not improve from 0.12946\n","Epoch 27/50\n","40/40 [==============================] - 3s 73ms/step - loss: 0.1094 - acc: 0.9628 - val_loss: 0.8301 - val_acc: 0.8903\n","\n","Epoch 00027: loss improved from 0.12946 to 0.12758, saving model to blstm.hdf5\n","Epoch 28/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1005 - acc: 0.9638 - val_loss: 0.7534 - val_acc: 0.8840\n","\n","Epoch 00028: loss improved from 0.12758 to 0.11580, saving model to blstm.hdf5\n","Epoch 29/50\n","40/40 [==============================] - 3s 77ms/step - loss: 0.1214 - acc: 0.9601 - val_loss: 0.8321 - val_acc: 0.8715\n","\n","Epoch 00029: loss improved from 0.11580 to 0.11502, saving model to blstm.hdf5\n","Epoch 30/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1203 - acc: 0.9641 - val_loss: 0.7665 - val_acc: 0.8683\n","\n","Epoch 00030: loss did not improve from 0.11502\n","Epoch 31/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1051 - acc: 0.9669 - val_loss: 0.7787 - val_acc: 0.8746\n","\n","Epoch 00031: loss did not improve from 0.11502\n","Epoch 32/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.1216 - acc: 0.9606 - val_loss: 0.8308 - val_acc: 0.8683\n","\n","Epoch 00032: loss did not improve from 0.11502\n","Epoch 33/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0997 - acc: 0.9704 - val_loss: 0.8628 - val_acc: 0.8715\n","\n","Epoch 00033: loss improved from 0.11502 to 0.10572, saving model to blstm.hdf5\n","Epoch 34/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0817 - acc: 0.9756 - val_loss: 0.8166 - val_acc: 0.8903\n","\n","Epoch 00034: loss improved from 0.10572 to 0.10252, saving model to blstm.hdf5\n","Epoch 35/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0999 - acc: 0.9677 - val_loss: 0.7650 - val_acc: 0.8934\n","\n","Epoch 00035: loss did not improve from 0.10252\n","Epoch 36/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0835 - acc: 0.9740 - val_loss: 0.9143 - val_acc: 0.8871\n","\n","Epoch 00036: loss improved from 0.10252 to 0.09558, saving model to blstm.hdf5\n","Epoch 37/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0830 - acc: 0.9765 - val_loss: 0.8673 - val_acc: 0.8934\n","\n","Epoch 00037: loss did not improve from 0.09558\n","Epoch 38/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0931 - acc: 0.9587 - val_loss: 0.9111 - val_acc: 0.8746\n","\n","Epoch 00038: loss improved from 0.09558 to 0.08728, saving model to blstm.hdf5\n","Epoch 39/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0940 - acc: 0.9726 - val_loss: 0.8797 - val_acc: 0.8777\n","\n","Epoch 00039: loss did not improve from 0.08728\n","Epoch 40/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0784 - acc: 0.9761 - val_loss: 1.0106 - val_acc: 0.8903\n","\n","Epoch 00040: loss improved from 0.08728 to 0.08682, saving model to blstm.hdf5\n","Epoch 41/50\n","40/40 [==============================] - 3s 71ms/step - loss: 0.0916 - acc: 0.9744 - val_loss: 0.8824 - val_acc: 0.8746\n","\n","Epoch 00041: loss did not improve from 0.08682\n","Epoch 42/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0732 - acc: 0.9796 - val_loss: 0.9147 - val_acc: 0.8871\n","\n","Epoch 00042: loss did not improve from 0.08682\n","Epoch 43/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0743 - acc: 0.9767 - val_loss: 1.0459 - val_acc: 0.8903\n","\n","Epoch 00043: loss improved from 0.08682 to 0.08599, saving model to blstm.hdf5\n","Epoch 44/50\n","40/40 [==============================] - 3s 73ms/step - loss: 0.0921 - acc: 0.9732 - val_loss: 1.1690 - val_acc: 0.8966\n","\n","Epoch 00044: loss did not improve from 0.08599\n","Epoch 45/50\n","40/40 [==============================] - 3s 73ms/step - loss: 0.0705 - acc: 0.9774 - val_loss: 0.9664 - val_acc: 0.8966\n","\n","Epoch 00045: loss improved from 0.08599 to 0.07720, saving model to blstm.hdf5\n","Epoch 46/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0621 - acc: 0.9795 - val_loss: 1.0658 - val_acc: 0.8746\n","\n","Epoch 00046: loss did not improve from 0.07720\n","Epoch 47/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0797 - acc: 0.9764 - val_loss: 0.8208 - val_acc: 0.8903\n","\n","Epoch 00047: loss did not improve from 0.07720\n","Epoch 48/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0817 - acc: 0.9705 - val_loss: 0.9138 - val_acc: 0.8809\n","\n","Epoch 00048: loss improved from 0.07720 to 0.07299, saving model to blstm.hdf5\n","Epoch 49/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0604 - acc: 0.9835 - val_loss: 1.1575 - val_acc: 0.8871\n","\n","Epoch 00049: loss improved from 0.07299 to 0.06577, saving model to blstm.hdf5\n","Epoch 50/50\n","40/40 [==============================] - 3s 72ms/step - loss: 0.0861 - acc: 0.9807 - val_loss: 1.2457 - val_acc: 0.8966\n","\n","Epoch 00050: loss did not improve from 0.06577\n","{'loss': [1.061893343925476, 0.7238373756408691, 0.6254358887672424, 0.5110208988189697, 0.48778122663497925, 0.4174230396747589, 0.4104352593421936, 0.380097895860672, 0.349996417760849, 0.3265362083911896, 0.3025963604450226, 0.3067111670970917, 0.27176734805107117, 0.26218023896217346, 0.24045108258724213, 0.23196449875831604, 0.21105720102787018, 0.20588435232639313, 0.19069500267505646, 0.16744054853916168, 0.1580636352300644, 0.167440265417099, 0.14665226638317108, 0.13394388556480408, 0.12945614755153656, 0.13400986790657043, 0.12758184969425201, 0.11579812318086624, 0.11501903831958771, 0.1257518231868744, 0.12019148468971252, 0.11891558766365051, 0.10571639984846115, 0.10252006351947784, 0.11005407571792603, 0.09557504951953888, 0.1026633158326149, 0.08728130161762238, 0.09683394432067871, 0.08681749552488327, 0.08977919071912766, 0.09228459000587463, 0.08599443733692169, 0.08830498158931732, 0.07720204442739487, 0.08029565215110779, 0.09094168990850449, 0.0729917660355568, 0.06576530635356903, 0.07178375869989395], 'acc': [0.7244898080825806, 0.7684458494186401, 0.8045526146888733, 0.8414442539215088, 0.8524332642555237, 0.8728414177894592, 0.8783359527587891, 0.8783359527587891, 0.894819438457489, 0.8940345644950867, 0.9034537076950073, 0.901098906993866, 0.9160125851631165, 0.9191522598266602, 0.9324960708618164, 0.930141270160675, 0.9324960708618164, 0.9317111372947693, 0.9332810044288635, 0.9497645497322083, 0.9505494236946106, 0.9466248154640198, 0.9505494236946106, 0.9583987593650818, 0.9631083011627197, 0.9583987593650818, 0.9591836929321289, 0.9607535600662231, 0.9631083011627197, 0.9583987593650818, 0.9583987593650818, 0.9615384340286255, 0.9686028361320496, 0.9654631018638611, 0.9670329689979553, 0.9686028361320496, 0.9693877696990967, 0.9670329689979553, 0.9756671786308289, 0.9725274443626404, 0.9725274443626404, 0.9756671786308289, 0.9725274443626404, 0.9733123779296875, 0.9772370457649231, 0.976452112197876, 0.9701727032661438, 0.9772370457649231, 0.9811617136001587, 0.9819466471672058], 'val_loss': [0.8860674500465393, 1.0166395902633667, 0.627155065536499, 0.6267455816268921, 0.6178532242774963, 0.5982184410095215, 0.515150249004364, 0.5474690794944763, 0.552861213684082, 0.5805760025978088, 0.7458680272102356, 0.6362380385398865, 0.5737676620483398, 0.5091139674186707, 0.506268322467804, 0.5669358968734741, 0.5210191011428833, 0.6543902158737183, 0.5597375631332397, 0.5529879927635193, 0.5855551958084106, 0.6296080350875854, 0.7152745127677917, 0.8006532192230225, 0.6219619512557983, 0.7461807727813721, 0.8300768136978149, 0.7533749938011169, 0.8321033716201782, 0.7664774060249329, 0.7786681652069092, 0.8308230638504028, 0.8628401160240173, 0.8166021704673767, 0.7650238871574402, 0.9142811894416809, 0.8672919869422913, 0.9111366271972656, 0.8797444105148315, 1.0105665922164917, 0.882419228553772, 0.9146552681922913, 1.0458714962005615, 1.1690260171890259, 0.9664191007614136, 1.0658208131790161, 0.8208287358283997, 0.9137639403343201, 1.1575403213500977, 1.245703101158142], 'val_acc': [0.705329179763794, 0.7272727489471436, 0.7993730306625366, 0.8087774515151978, 0.8119122385978699, 0.7931034564971924, 0.8401253819465637, 0.8307210206985474, 0.8338558077812195, 0.815047025680542, 0.8369905948638916, 0.8589341640472412, 0.8620689511299133, 0.8871473073959351, 0.8746081590652466, 0.852664589881897, 0.8620689511299133, 0.8746081590652466, 0.8840125203132629, 0.8840125203132629, 0.8652037382125854, 0.8369905948638916, 0.8777429461479187, 0.8683385848999023, 0.8965517282485962, 0.8777429461479187, 0.890282154083252, 0.8840125203132629, 0.8714733719825745, 0.8683385848999023, 0.8746081590652466, 0.8683385848999023, 0.8714733719825745, 0.890282154083252, 0.8934169411659241, 0.8871473073959351, 0.8934169411659241, 0.8746081590652466, 0.8777429461479187, 0.890282154083252, 0.8746081590652466, 0.8871473073959351, 0.890282154083252, 0.8965517282485962, 0.8965517282485962, 0.8746081590652466, 0.890282154083252, 0.8808777332305908, 0.8871473073959351, 0.8965517282485962]}\n"],"name":"stdout"}]}]}