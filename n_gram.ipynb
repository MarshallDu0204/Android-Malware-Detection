{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"n_gram.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNmBI8/XjA0w2XYy99HUk55"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DWeRoHoXwySD","executionInfo":{"status":"ok","timestamp":1612757462971,"user_tz":300,"elapsed":2715,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}}},"source":["import csv\n","import os\n","\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Embedding,Dense,Bidirectional,LSTM,Dropout,TimeDistributed,Flatten,InputSpec,MaxPooling1D\n","from keras.callbacks import ModelCheckpoint\n","from keras import Input,Model\n","from keras import backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers as initializers, regularizers, constraints\n","\n","from sklearn import tree\n","from sklearn import svm\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import AdaBoostClassifier"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PYunXX3w30R","executionInfo":{"status":"ok","timestamp":1612757480472,"user_tz":300,"elapsed":17495,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}},"outputId":"ea1ad19e-4f40-4bbe-a3fa-d5eb8ee5c732"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0xM_mev-w5zr","executionInfo":{"status":"ok","timestamp":1612759324066,"user_tz":300,"elapsed":345,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}}},"source":["def gram_data(label_path = 'drive/MyDrive/Colab Notebooks/apk_label.csv',dim = 2,one_hot = True,whole_data = False,binary_label = False,n_gram = 3):\n","    \n","    data_path = 'drive/MyDrive/Colab Notebooks/' + str(n_gram) + '_gram.csv' \n","    \n","    with open(label_path,'r',encoding = 'utf-8') as f:\n","        lines = f.readlines()\n","        tmp_label  = lines[0].split(',')\n","        apk_label = []\n","        for item in tmp_label:\n","            apk_label.append(int(item))\n","\n","    with open(data_path,'r',encoding = 'utf-8') as f1:\n","        lines = f1.readlines()\n","        train_data = []\n","\n","        for i in range(1,len(lines)):\n","            tmp_data = lines[i]\n","            tmp_data = tmp_data.split(\",\")\n","            tmp_data[-1] = tmp_data[-1].strip()\n","            int_data = []\n","            for item in tmp_data:\n","                int_data.append(int(item))\n","            train_data.append(int_data)\n","\n","    bi_label = []\n","    if binary_label:\n","        for item in apk_label:\n","            if item == 0:\n","                bi_label.append(0)\n","            else:\n","                bi_label.append(1)\n","        apk_label = bi_label\n","\n","    apk_label = np.array(apk_label)\n","\n","    if one_hot:\n","\n","        if binary_label:\n","\n","            apk_label = keras.utils.to_categorical(apk_label,num_classes = 2)\n","\n","        else:\n","            apk_label = keras.utils.to_categorical(apk_label,num_classes = 5)\n","\n","    train_data = np.array(train_data)\n","\n","    if dim == 3:\n","        train_data = np.reshape(train_data,(len(train_data),train_data.shape[1],1))\n","\n","    if whole_data == True:\n","            \n","        return train_data,apk_label\n","\n","    else:\n","\n","        data_train, data_test, label_train, label_test = train_test_split(train_data,apk_label,test_size=0.2,random_state=None,shuffle=True)\n","            \n","        return data_train,data_test,label_train,label_test\n"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0D-llgGyzmrf","executionInfo":{"status":"ok","timestamp":1612758499162,"user_tz":300,"elapsed":22049,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}},"outputId":"e61296d0-7350-49a3-a39d-d7c60b2fe3bc"},"source":["data,label = gram_data(dim = 2,one_hot = False,whole_data = True,binary_label=False)\n","#print(data_train)\n","clf = svm.SVC()\n","#clf = LogisticRegression(random_state=0)\n","#clf = tree.DecisionTreeClassifier()\n","#clf.fit(data, label)\n","#clf = GaussianNB()\n","#clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n","#pred = clf.predict(data_test)\n","#print(pred)\n","scores = cross_val_score(clf, data, label, cv=5,scoring='accuracy')\n","print(scores.mean())"],"execution_count":32,"outputs":[{"output_type":"stream","text":["0.8407178144158085\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U3ZzKsNz0upg","executionInfo":{"status":"ok","timestamp":1612759697834,"user_tz":300,"elapsed":448,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}}},"source":["class MLP():\n","\n","    data_train = \"\"\n","    data_test = \"\"\n","    label_train = \"\"\n","    label_test = \"\"\n","\n","    def __init__(self,data_train,data_test,label_train,label_test,model_width = 512):\n","        self.data_train = data_train\n","        self.data_test = data_test\n","        self.label_train = label_train\n","        self.label_test = label_test\n","        self.model_width = model_width\n","\n","    def mlpModel(self,pretrained_weights = None):\n","\n","        input = Input(shape = (self.data_train.shape[1],))\n","\n","        hiddenLayer = Dense(self.model_width,activation='relu')(input)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","\n","        hiddenLayer = Dense(self.model_width,activation='relu')(hiddenLayer)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","\n","        hiddenLayer = Dense(self.model_width,activation='relu')(hiddenLayer)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","        \n","        hiddenLayer = Dense(self.model_width,activation='relu')(hiddenLayer)\n","        hiddenLayer = Dropout(0.3)(hiddenLayer)\n","\n","        output = Dense(5,activation = 'softmax')(hiddenLayer)\n","\n","        model = Model(inputs=input, outputs=[output])\n","\n","        model.compile(\n","            optimizer='rmsprop',\n","            loss='categorical_crossentropy',\n","            metrics=['acc']\n","        )\n","\n","        if (pretrained_weights):\n","            model.load_weights(pretrained_weights)\n","\n","        return model\n","    \n","    def train(self,model):\n","\n","        model_checkpoint = ModelCheckpoint('mlp.hdf5',monitor = 'loss',verbose = 1,save_best_only = True)\n","\n","        history = model.fit(\n","            x = self.data_train,\n","            y = self.label_train,\n","            validation_data = (self.data_test,self.label_test),\n","            batch_size = 64,\n","            epochs = 50,\n","            callbacks = [model_checkpoint]\n","        )\n","\n","        return history.history['loss'],history.history['acc'],history.history['val_loss'],history.history['val_loss']\n","\n","class BLSTM():\n","\n","    data_train = \"\"\n","    data_test = \"\"\n","    label_train = \"\"\n","    label_test = \"\"\n","\n","    def __init__(self,data_train,data_test,label_train,label_test,model_width = 256):\n","        self.data_train = data_train\n","        self.data_test = data_test\n","        self.label_train = label_train\n","        self.label_test = label_test\n","        self.model_width = model_width\n","\n","    \n","    def lstmModel_timedis(self,pretrained_weights = None):\n","\n","        inputContent = Input(shape = (self.data_train.shape[1],1),name = 'content')\n","\n","        lstmContent = Bidirectional(LSTM(self.model_width,return_sequences=True),merge_mode='ave')(inputContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        lstmContent = Bidirectional(LSTM(self.model_width,return_sequences=True),merge_mode='ave')(inputContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        lstmContent = Bidirectional(LSTM(self.model_width,return_sequences=True),merge_mode='ave')(inputContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        lstmContent = Bidirectional(LSTM(self.model_width,return_sequences=True),merge_mode='ave')(lstmContent)\n","        lstmContent = Dropout(0.2)(lstmContent)\n","\n","        output = TimeDistributed(Dense(self.model_width,activation='relu'))(lstmContent)\n","        output = Dropout(0.2)(output)\n","\n","        output = Flatten()(output)\n","\n","        output = Dense(128,activation='relu')(output)\n","        output = Dropout(0.2)(output)\n","        \n","        output = Dense(5,activation = 'softmax')(output)\n","\n","        model = Model(inputs=inputContent, outputs=[output])\n","\n","        model.compile(\n","            optimizer='rmsprop',\n","            loss='categorical_crossentropy',\n","            metrics=['acc']\n","        )\n","\n","        if (pretrained_weights):\n","            model.load_weights(pretrained_weights)\n","\n","        return model\n","\n","    def train(self,model):\n","\n","        model_checkpoint = ModelCheckpoint('blstm.hdf5',monitor = 'loss',verbose = 1,save_best_only = True)\n","\n","        history = model.fit(\n","            x = self.data_train,\n","            y = self.label_train,\n","            validation_data = (self.data_test,self.label_test),\n","            batch_size = 32,\n","            epochs = 50,\n","            callbacks = [model_checkpoint]\n","        )\n","\n","        print(history.history)\n","\n","        return history.history['loss'],history.history['acc'],history.history['val_loss'],history.history['val_acc']\n","\n"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5cY68X81Axy","executionInfo":{"status":"ok","timestamp":1612759733277,"user_tz":300,"elapsed":278,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}}},"source":["def writeResult(model_name,loss,acc,val_loss,val_acc):\n","    filePath = 'drive/MyDrive/Colab Notebooks/'+str(model_name)+'.txt'\n","    with open(filePath,'a') as f:\n","        pass\n","\n","\n","def main():\n","    #data_train,data_test,label_train,label_test = gram_data(dim = 3,n_gram = 3)\n","    #print(data_train.shape)\n","    #rnn = BLSTM(data_train,data_test,label_train,label_test)\n","    #model = rnn.lstmModel_timedis()\n","    #model.summary()\n","    \n","    #loss,acc,val_loss,val_acc = rnn.train(model)\n","\n","\n","    data_train,data_test,label_train,label_test = gram_data(dim = 2,n_gram = 5)\n","    #print(data_train.shape)\n","    \n","    mlp_model = MLP(data_train,data_test,label_train,label_test,model_width=512)\n","    model = mlp_model.mlpModel()\n","    #model.summary()\n","\n","    loss,acc,val_loss,val_acc = mlp_model.train(model)"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTA_Fx1Z1nN6","executionInfo":{"status":"ok","timestamp":1612759770056,"user_tz":300,"elapsed":35843,"user":{"displayName":"Wei Du","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSYjh_coOP21rLLQ1IuLbenNxGkjMopgeZ3SWq=s64","userId":"01425178066782527725"}},"outputId":"28cca3e6-6fe1-4c2f-c961-b5f0039a40ef"},"source":["main()"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","20/20 [==============================] - 1s 21ms/step - loss: 6.1097 - acc: 0.5761 - val_loss: 0.8147 - val_acc: 0.6918\n","\n","Epoch 00001: loss improved from inf to 3.05822, saving model to mlp.hdf5\n","Epoch 2/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.8840 - acc: 0.7251 - val_loss: 0.7677 - val_acc: 0.7138\n","\n","Epoch 00002: loss improved from 3.05822 to 0.81425, saving model to mlp.hdf5\n","Epoch 3/50\n","20/20 [==============================] - 0s 16ms/step - loss: 0.8255 - acc: 0.7447 - val_loss: 0.8991 - val_acc: 0.7862\n","\n","Epoch 00003: loss did not improve from 0.81425\n","Epoch 4/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.7091 - acc: 0.7816 - val_loss: 0.6171 - val_acc: 0.7956\n","\n","Epoch 00004: loss improved from 0.81425 to 0.71118, saving model to mlp.hdf5\n","Epoch 5/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.5767 - acc: 0.8116 - val_loss: 0.5778 - val_acc: 0.8679\n","\n","Epoch 00005: loss improved from 0.71118 to 0.56941, saving model to mlp.hdf5\n","Epoch 6/50\n","20/20 [==============================] - 0s 16ms/step - loss: 0.4956 - acc: 0.8639 - val_loss: 0.4604 - val_acc: 0.8616\n","\n","Epoch 00006: loss improved from 0.56941 to 0.52289, saving model to mlp.hdf5\n","Epoch 7/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3776 - acc: 0.8909 - val_loss: 0.4546 - val_acc: 0.8491\n","\n","Epoch 00007: loss improved from 0.52289 to 0.44559, saving model to mlp.hdf5\n","Epoch 8/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.3314 - acc: 0.9016 - val_loss: 0.3851 - val_acc: 0.8742\n","\n","Epoch 00008: loss improved from 0.44559 to 0.33297, saving model to mlp.hdf5\n","Epoch 9/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.3282 - acc: 0.9183 - val_loss: 0.4688 - val_acc: 0.8994\n","\n","Epoch 00009: loss did not improve from 0.33297\n","Epoch 10/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2552 - acc: 0.9300 - val_loss: 0.4989 - val_acc: 0.8742\n","\n","Epoch 00010: loss improved from 0.33297 to 0.28587, saving model to mlp.hdf5\n","Epoch 11/50\n","20/20 [==============================] - 1s 33ms/step - loss: 0.2174 - acc: 0.9382 - val_loss: 0.4899 - val_acc: 0.8711\n","\n","Epoch 00011: loss improved from 0.28587 to 0.27053, saving model to mlp.hdf5\n","Epoch 12/50\n","20/20 [==============================] - 0s 15ms/step - loss: 0.1852 - acc: 0.9546 - val_loss: 0.4461 - val_acc: 0.8648\n","\n","Epoch 00012: loss did not improve from 0.27053\n","Epoch 13/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1726 - acc: 0.9562 - val_loss: 0.3995 - val_acc: 0.9025\n","\n","Epoch 00013: loss improved from 0.27053 to 0.18210, saving model to mlp.hdf5\n","Epoch 14/50\n","20/20 [==============================] - 0s 15ms/step - loss: 0.4347 - acc: 0.8933 - val_loss: 0.4446 - val_acc: 0.8931\n","\n","Epoch 00014: loss did not improve from 0.18210\n","Epoch 15/50\n","20/20 [==============================] - 0s 15ms/step - loss: 0.1541 - acc: 0.9601 - val_loss: 0.4391 - val_acc: 0.8805\n","\n","Epoch 00015: loss improved from 0.18210 to 0.17050, saving model to mlp.hdf5\n","Epoch 16/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1672 - acc: 0.9627 - val_loss: 0.6465 - val_acc: 0.8836\n","\n","Epoch 00016: loss did not improve from 0.17050\n","Epoch 17/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2622 - acc: 0.9406 - val_loss: 0.4033 - val_acc: 0.9119\n","\n","Epoch 00017: loss did not improve from 0.17050\n","Epoch 18/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1604 - acc: 0.9566 - val_loss: 0.4811 - val_acc: 0.8899\n","\n","Epoch 00018: loss did not improve from 0.17050\n","Epoch 19/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1981 - acc: 0.9517 - val_loss: 0.4065 - val_acc: 0.8899\n","\n","Epoch 00019: loss did not improve from 0.17050\n","Epoch 20/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1340 - acc: 0.9655 - val_loss: 0.4318 - val_acc: 0.9057\n","\n","Epoch 00020: loss improved from 0.17050 to 0.16262, saving model to mlp.hdf5\n","Epoch 21/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2578 - acc: 0.9436 - val_loss: 0.4963 - val_acc: 0.9088\n","\n","Epoch 00021: loss did not improve from 0.16262\n","Epoch 22/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1460 - acc: 0.9590 - val_loss: 0.4940 - val_acc: 0.8742\n","\n","Epoch 00022: loss did not improve from 0.16262\n","Epoch 23/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1257 - acc: 0.9602 - val_loss: 1.0385 - val_acc: 0.8396\n","\n","Epoch 00023: loss improved from 0.16262 to 0.12224, saving model to mlp.hdf5\n","Epoch 24/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.2554 - acc: 0.9390 - val_loss: 0.4712 - val_acc: 0.9088\n","\n","Epoch 00024: loss did not improve from 0.12224\n","Epoch 25/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1834 - acc: 0.9526 - val_loss: 0.4368 - val_acc: 0.8962\n","\n","Epoch 00025: loss did not improve from 0.12224\n","Epoch 26/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1201 - acc: 0.9601 - val_loss: 0.5901 - val_acc: 0.9057\n","\n","Epoch 00026: loss did not improve from 0.12224\n","Epoch 27/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1106 - acc: 0.9726 - val_loss: 0.7790 - val_acc: 0.9057\n","\n","Epoch 00027: loss did not improve from 0.12224\n","Epoch 28/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1157 - acc: 0.9788 - val_loss: 0.7473 - val_acc: 0.8679\n","\n","Epoch 00028: loss did not improve from 0.12224\n","Epoch 29/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1637 - acc: 0.9579 - val_loss: 0.7053 - val_acc: 0.8899\n","\n","Epoch 00029: loss did not improve from 0.12224\n","Epoch 30/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1349 - acc: 0.9604 - val_loss: 0.7372 - val_acc: 0.9057\n","\n","Epoch 00030: loss did not improve from 0.12224\n","Epoch 31/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1109 - acc: 0.9649 - val_loss: 0.8594 - val_acc: 0.9025\n","\n","Epoch 00031: loss improved from 0.12224 to 0.11768, saving model to mlp.hdf5\n","Epoch 32/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1429 - acc: 0.9548 - val_loss: 0.8753 - val_acc: 0.8931\n","\n","Epoch 00032: loss improved from 0.11768 to 0.11573, saving model to mlp.hdf5\n","Epoch 33/50\n","20/20 [==============================] - 0s 24ms/step - loss: 0.0612 - acc: 0.9808 - val_loss: 0.7224 - val_acc: 0.9182\n","\n","Epoch 00033: loss improved from 0.11573 to 0.07524, saving model to mlp.hdf5\n","Epoch 34/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1330 - acc: 0.9698 - val_loss: 0.8819 - val_acc: 0.9119\n","\n","Epoch 00034: loss did not improve from 0.07524\n","Epoch 35/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0841 - acc: 0.9805 - val_loss: 0.9135 - val_acc: 0.9057\n","\n","Epoch 00035: loss did not improve from 0.07524\n","Epoch 36/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0686 - acc: 0.9785 - val_loss: 1.0968 - val_acc: 0.8962\n","\n","Epoch 00036: loss did not improve from 0.07524\n","Epoch 37/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1808 - acc: 0.9545 - val_loss: 0.7720 - val_acc: 0.9119\n","\n","Epoch 00037: loss did not improve from 0.07524\n","Epoch 38/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1205 - acc: 0.9558 - val_loss: 1.1087 - val_acc: 0.9088\n","\n","Epoch 00038: loss did not improve from 0.07524\n","Epoch 39/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0718 - acc: 0.9778 - val_loss: 0.6838 - val_acc: 0.9340\n","\n","Epoch 00039: loss did not improve from 0.07524\n","Epoch 40/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1203 - acc: 0.9642 - val_loss: 0.6899 - val_acc: 0.9214\n","\n","Epoch 00040: loss did not improve from 0.07524\n","Epoch 41/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0390 - acc: 0.9874 - val_loss: 1.0395 - val_acc: 0.9308\n","\n","Epoch 00041: loss improved from 0.07524 to 0.04989, saving model to mlp.hdf5\n","Epoch 42/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1012 - acc: 0.9670 - val_loss: 0.6884 - val_acc: 0.8962\n","\n","Epoch 00042: loss did not improve from 0.04989\n","Epoch 43/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.1248 - acc: 0.9673 - val_loss: 0.9603 - val_acc: 0.9277\n","\n","Epoch 00043: loss did not improve from 0.04989\n","Epoch 44/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0569 - acc: 0.9874 - val_loss: 0.7729 - val_acc: 0.9245\n","\n","Epoch 00044: loss did not improve from 0.04989\n","Epoch 45/50\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0976 - acc: 0.9657 - val_loss: 1.2086 - val_acc: 0.9182\n","\n","Epoch 00045: loss did not improve from 0.04989\n","Epoch 46/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0869 - acc: 0.9779 - val_loss: 0.8890 - val_acc: 0.9025\n","\n","Epoch 00046: loss did not improve from 0.04989\n","Epoch 47/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0930 - acc: 0.9667 - val_loss: 0.7982 - val_acc: 0.9182\n","\n","Epoch 00047: loss did not improve from 0.04989\n","Epoch 48/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0596 - acc: 0.9846 - val_loss: 0.7413 - val_acc: 0.9119\n","\n","Epoch 00048: loss did not improve from 0.04989\n","Epoch 49/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1073 - acc: 0.9696 - val_loss: 1.0921 - val_acc: 0.9182\n","\n","Epoch 00049: loss did not improve from 0.04989\n","Epoch 50/50\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0538 - acc: 0.9769 - val_loss: 1.9925 - val_acc: 0.9182\n","\n","Epoch 00050: loss improved from 0.04989 to 0.04853, saving model to mlp.hdf5\n"],"name":"stdout"}]}]}